@article{CONATI2021103503,
title = {Toward personalized XAI: A case study in intelligent tutoring systems},
journal = {Artificial Intelligence},
volume = {298},
pages = {103503},
year = {2021},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2021.103503},
url = {https://www.sciencedirect.com/science/article/pii/S0004370221000540},
author = {Cristina Conati and Oswald Barral and Vanessa Putnam and Lea Rieger},
keywords = {Explainable artificial intelligence (XAI), Intelligent tutoring systems (ITS), User modeling, Personalization},
abstract = {Our research is a step toward ascertaining the need for personalization in XAI, and we do so in the context of investigating the value of explanations of AI-driven hints and feedback in Intelligent Tutoring Systems (ITS). We added an explanation functionality to the Adaptive CSP (ACSP) applet, an interactive simulation that helps students learn an algorithm for constraint satisfaction problems by providing AI-driven hints adapted to their predicted level of learning. We present the design of the explanation functionality and the results of a controlled study to evaluate its impact on students' learning and perception of the ACPS hints. The study includes an analysis of how these outcomes are modulated by several user characteristics such as personality traits and cognitive abilities, to asses if explanations should be personalized to these characteristics. Our results indicate that providing explanations increase students' trust in the ACPS hints, perceived usefulness of the hints, and intention to use them again. In addition, we show that students' access of the ACSP explanation and learning gains are modulated by three user characteristics, Need for Cognition, Contentiousness and Reading Proficiency, providing insights on how to personalize the ACSP explanations to these traits, as well as initial evidence on the potential value of personalized Explainable AI (XAI) for ITS.}
}